# Twitter-Sentiment-Analysis

##SadrÅ¾aj 

KoliÄina informacija koja protiÄe druÅ¡tvenim mreÅ¾ama svakodnevno se poveÄ‡ava, i predstavlja bogat izvor podataka, koji ako se pravilno semantiÄki obradi, moÅ¾e biti veoma koristan u najrazliÄitijim oblastima. Cilj ovo projekta je analiza sentimenta Twitter poruka primenom algoritama maÅ¡inskog uÄenja. 

U radu su koriÅ¡Ä‡eni sledeÄ‡i algoritmi: Naivni Bajes, Maksimalna entropija i Metoda potpornih vektora. 

Osnovna ideja je prikupljanje tekstualnih podataka u cilju konstrukcije i evaluacije razliÄitih klasifikatora za analizu sentimenta Twitter poruka. Dobijeni klasifikatori su testirani i meÄ‘usobno uporeÄ‘eni u cilju pronalaska onog koji pruÅ¾a najbolje performance klasifikacije Twitter poruka. 

##Uvod

KoriÅ¡Ä‡enje Interneta kao komunikacionog kanala omoguÄ‡ilo je da druÅ¡tvene mreÅ¾e i servisi za mikroblogovanje postanu znaÄajan potencijalni izvor znanja koje se kasnijom semantiÄkom obradom i analizom mogu koristiti u procesima donoÅ¡enja odluka.

Velika koliÄina podataka koja se svakog dana generiÅ¡e putem interneta pripada nestruktuiranim podacima tekstualnog tipa. MaÅ¡insko uÄenje omoguÄ‡ava da sistem prepozna date reÄi i pripoji im neko smisleno znaÄenje. 

##Motiv za izbor Twitter aplikacije

Svakodnevni porast i prisutnost mobilnih ureÄ‘aja u svakodnevnom Å¾ivotu, u velikoj meri su olakÅ¡ali pristup druÅ¡tvenim mreÅ¾ama, i pojednostavili naÄin deljenja informacija jednim klikom. Mikroblogovanje kao jedan  od oblika druÅ¡tvenih mreÅ¾a se veÄ‡ uveliko integrisao u svakodnevni Å¾ivot i postao deo svakodnevne komunikacije i razmene informacija. Smatra se da su podaci proizvedeni mikroblogovanjem nedvosmisleni, brzi i pristupaÄni. Twitter, kao najpoznatiji servis za mikrobloging, izuzetno je pogodan je za procenu stava ogromnog broja korisnika. 

Pored toga, podaci sa Twitter-a su posebno interesantni jer se poruke pojavljuju â€brzinom misliâ€œ odnosno dostupni su za preuzimanje momentalno, jer se sve odigrava u â€skoro realnom vremenuâ€œ (eng. near real-time).  

##Definicija anlalize sentimenta

Analiza sentimenta Twitter poruke obuhvata process odreÄ‘ivanja emotivnog tona na osnovu niza reÄi a koristi se kako bi se steklo razumevanje stava, miÅ¡ljenja i emocija koji su izraÅ¾eni u okviru online poruke. U ovom radu koriÅ¡Ä‡ena je binarna klasifikacija twitter poruke u dve klase: pozitivnu i negativnu.
ÄŒesto moÅ¾e biti neogreÄ‘eno da li odreÄ‘ena twitter poruka sadrÅ¾i emociju. Takve twitter poruke nazivamo neutralnim. MeÄ‘utim, u ovom radu neutralne poruke nisu uzete u razmatranje prilikom analize sentimenta.  

Za treniranje odreÄ‘enog klasifikatora, najÄeÅ¡Ä‡e su potrebni ruÄno obeleÅ¾eni podaci. MeÄ‘utim sa velikim brojem tema koje su diskutovane na Twitter-u bilo bi teÅ¡ko prikupiti veliki broj twitter poruka koji je potreban za trening klasifikatora. Stoga, u ovom radu koriÅ¡Ä‡ena je automatska ekstrakcija oseÄ‡enja iz twitter poruka na osnovu emotikona. Na primer, emotikon :) ukazuje da se radi o poruci sa pozitivnom emocijom, dok emotikon :( ukazuje da je izraÅ¾ena negativna emocija.  

##Prikupljanje podataka putem Twitter API servisa

Twitter API (Application Programming Interface) je sistem za pristup Twitter serverima i bazi podataka radi ekstrakcije rezultata upita. 
Twitter servis svima stavlja na raspolaganje sve informacije od onog momenta kada su objavljene. Putem Twitter API servisa omoguÄ‡en je pristup popularnim ili nedavnim twitter porukama koje su objavljene u poslednjih 7 dana. TakoÄ‘e moguÄ‡e je pristupiti i podacima o geolokaciji svake Twitter poruke.  Na taj naÄin omoguÄ‡eno prouÄavanje kako tekstualnih tako i lokacijskih karakteristika online sadrÅ¾aja.

Upiti se Å¡alju u obliku url adrese, i u sebi sadrÅ¾e kljuÄne reÄi pretrage i druge parametre. Naravno postoje ograniÄenja sa serverske strane o broju upita, odnosno zahteva koje se mogu uputiti u minuti. 
U ovom radu koriÅ¡Ä‡en je Twitter Search API, koji za razliku od Stream API-ja poseduje odreÄ‘ena ograniÄenja prilikom slanja upita i pretraÅ¾ivanja podataka. Upiti koji pretraÅ¾uju tvitove mogu da vrate maksimalno do 100 tvitova po jednom upitu. TakoÄ‘e kao Å¡to je veÄ‡ naglaÅ¡eno, nije moguÄ‡e pretraÅ¾ivati stare tvitove, veÄ‡ samo one objavljene u proteklih sedam dana.

Razvijene su mnogobrojne biblioteke za razliÄite programske jezike koje koriste Twitter API za pretragu podataka, odnosno text mining. U ovom radu koriÅ¡Ä‡ene su biblioteke za R programski jezik meÄ‘u kojima su najbitnije: twitteR, tm(text mining), RTextTools, e1071 i caret.
Za preuzimanje podataka putem Twitter API servisa moÅ¾emo izdvojiti sledeÄ‡e glavne korake:

â€¢	Kreiranje  i registrovanje aplikacije na razvojnoj stranici Twitter-a
â€¢	Preuzimanje neophodnih biblioteka za R programski jezik
â€¢	Pokretanje upita i Äuvanje podataka

###Kreiranje  i registrovanje aplikacije na razvojnoj stranici Twitter-a

S obzirom da Twitter zahteva autorizaciju prilikom koriÅ¡Ä‡enja svojih servisa, bilo je neophodno kreirati i registrovati aplikaciju na razvojnoj stranici Twitter-a. Postoji moguÄ‡nost i autorizacije bez aplikacije, ali su tada ograniÄenja veÄ‡a, pa je zbog toga odluÄeno  da se koristi OAuth 1 sistem autorizacije koji poseduje Äetiri parametra za pristup: 
â€¢	API key,
â€¢	API secret,
â€¢	Access Token 
â€¢	Access Token Secret.
Ovi parametri su trajni kada se jednom kreiraju, pa ih je moguÄ‡e koristiti dok god postoji registrovana aplikacija. 
Nakon kreiranja aplikacije, preuzeti parametri su saÄuvani dokumentu pod nazivom twitter_auth.csv.


Slika 1 SadrÅ¾aj fajla twitter_auth.csv

Autorizacija je uspostavljenja koriÅ¡Ä‡enjem raspoloÅ¾ive funkcije setup_twitter_oauth() kojoj su prosleÄ‘eni dati parametri. 

###Izbor kljuÄne reÄi za pretragu
Biblioteka twitteR nudi moguÄ‡nost sagledavanja trenda, odnostno aktuelne teme za odreÄ‘eno geografsko podruÄje. Funkcjia availableTrendLocations() vraÄ‡a informacije o trenutno dostupnim lokacijama uz njihov woeid (where on Earth ID). 
Stoga, moÅ¾emo koristiti funkciju getTrends() koja prikazuje trenutne trendove za specificirani woeid traÅ¾ene lokacije. Ukoliko Å¾elimo pretragu za ceo svet, woeid iznosi 1. 

Radi kreiranja boljih klasifikatora cilj je prikupiti Å¡to veÄ‡i uzorak. Zbog toga Ä‡emo najpre izvrÅ¡titi analizu trendova u celom svetu, prema objaÅ¡njenom postupku, kako bismo prikupili Å¡to veÄ‡i broj twitter poruka. Nakon sagledavanja aktuelnih tema, odluÄeno je da kljuÄna reÄ upita koji Ä‡e se korisiti bude hashtag #RussianGP (Russian Grand Prix).

 
###Formiranje i pokretanje upita

Da bismo mogli da prikupimo podatke putem Twitter API servisa neophodno je da ispoÅ¡tujemo odreÄ‘en format Search upita koji servis zahteva. Za pretragu Twitter-a koriÅ¡Ä‡ena je raspoloÅ¾iva funkcija searchTwitter().
Ukoliko Å¾elimo da izvrÅ¡imo jednostavnu pretragu po nekoj kljuÄnoj reÄi dovoljno je da funkciji prosledimo datu kljuÄnu reÄ. Za komplikovanije pretrage moguÄ‡e je koristiti razliÄite operatore kojima se moÅ¾e promeniti ponaÅ¡enja upita. U tabeli1 navedeni su neki od operatora koji su zajedno sa objaÅ¡njenim ponaÅ¡anjem dostupni u Twitter Search API dokumentaciji. 





Za preuzimanje twitter poruka koristili smo funkciju searchTwitter() koja nam je dostupna putem biblioteke twitteR. Data funkcija izvrÅ¡ava pretragu Twitter-a na osnovu prosleÄ‘enog stringa. Poseduje sledeÄ‡u sintaksu:

searchTwitter (searchString, n=25, lang=NULL, since=NULL, until=NULL, locale=NULL, geocode=NULL, sinceID=NULL, maxID=NULL, resultType=NULL, retryOnRateLimit=120)

Kako bismo izvrÅ¡ili testiranje klasifikatora neophodno je da pripremo 2 dataset-a sa twitter porukama, gde je svaka od njih oznaÄena kao pozitivna ili negativna. Jedan dataset sadrÅ¾i twitter poruke koje iskazuju pozitivni sentiment, dok Ä‡e drugi sadÅ¾ati poruke sa izraÅ¾enim negativnim emocijama. Funkciju searchTwitter() pozivamo dva puta za preuzimanje pozitivnih i negativnih poruka respektivno. 
Postoje razliÄiti emotikoni kojima se moÅ¾e izraziti pozitivna emocija ( :), :-), :D, :-D), kao i negativna. MeÄ‘utim, ako funkciji prosledimo samo jedan od pozitivnih emotikona :-), dobiÄ‡emo kao rezultat twitter poruke sa svim pozitivnim emotikonima. Pored broja twitter poruka, funkcija prima parametar kojim specificiramo jezik na kom vrÅ¡imo pretragu.




Date linije koda pokretane su nekoliko puta u cilju formiranja uzorka zadovoljavajuÄ‡ih dimenzija. Nakon prikupljanja twitter poruka formiran je dataframe-a sa strukturom koja je  prikazana u tabeli 2.

NAZIV PROMENLJIVE
TIP PROMENLJIVE
OPIS PROMENLJIVE
created
POSIXct
Datum i vreme nastanka twitter poruke
id
Character
ID poruke
text
Character
SadrÅ¾aj poruke
screenName
Character
KorisniÄko ime
retweetCount
Numeric
Broj ponovljenih poruka

Prikupljene  twitter poruke sa izraÅ¾enim pozitivnim I negativnim emocijama saÄuvane su u CSV dokumentima positiveTweets.csv i negativeTweets.scv respektivno. 

##Obrada twitter poruka

Za sprovoÄ‘enje sentiment analize potrebno je najpre izvrÅ¡iti obradu prikupljenih twitter poruka. 

Mnoge twitter poruke u sebi sadrÅ¾e linkove, oznake drugih osoba, cifre, znake interpunkcija, i mnoge druge simbole. Zbog toga je neophodno iz teksta svake twitter poruke ukloniti sve reÄi i simbole koji nisu od znaÄaja za samu sentiment analizu. 

TakoÄ‘e, uklonjeni su â€œretweetoviâ€, koji ukazuju na kopiranje neÄije twitter poruke i postavljanja preko drugog naloga. Ukoliko bi se takve twitter poruke uzele u razmatranje, tada bi jedna ista poruka bila ubrojana viÅ¡e puta, Å¡to Å¾elimo da izbegnemo. NJih prepoznajemo pomoÄ‡u oznake RT na poÄetku poruke. Nakon odstranjivanja date oznake uklanjamo sve ponovljene twitter poruke. Na taj naÄin sigurni smo da je svaka poruka meÄ‘u prikupljenim podacima unikatna. 


Congratulations to newest Flying Finn! Below every one is a shark ğŸ˜Š Making a great race out of a boring track/tyreâ€¦ https://t.co/BkR9deJFyQ
RT @niki01103: The bigest suprise of the day: First row for #ScuderiaFerrari ğŸ˜®#RussianGP #Formula1 #mifolyikittgyÃ¶ngyÃ¶sÃ¶n #sochigp https://â€¦
RT @redbullracing: Congrats to @ValtteriBottas on his first #F1 win #RussianGP #Ğ“Ñ€Ğ°Ğ½ĞŸÑ€Ğ¸Ğ Ğ¾ÑÑĞ¸Ğ¸ https://t.co/W4R4ZgFw05
U tabeli 3 navedeni su primeri twitter poruka pre obrade


SadrÅ¾aj navedenih poruka nakon primarne obrade prikazan je u tabeli 4.
 
congratulations to newest flying finn below every one is a shark  making a great race out of a boring tracktyre
the bigest suprise of the day first row for scuderiaferrari  formula mifolyikittgyngysn sochigp
congrats to  on his first f win  


Nakon prvobitne obrade i uklanjanja svih duplikata poruka, formiran je dataframe koji integriÅ¡e sve prikupljene poruke. Pored samog teksta poruke, dataframe sadrÅ¾i i promenljivu class koja deklariÅ¡e da li poruka sadrÅ¾i pozitivne ili negativne emocije. Za pozitivne poruke, class ima vrednost pos, dok za negativne poruke njena vrednost  iznosi neg. Navedeni dataframe saÄuvan je u dokumentu cleanTweets.csv.

##Tokenizacija i transformacija podataka

Za nastavak transformacije podataka koristimo funkciju tm_map() iz paketa tm. Data funkcija omoguÄ‡ava razliÄite transformacije tekta kao Å¡to su uklanjanje nepotrebnog praznog prostora i eliminacija uÄestanih reÄi engleskog jezika â€“ stopwords (Älanovi, veznici itd). 
Za potrebe kreiranja korpusa i transformacije podataka formirana je dodatna funkcija createAndCleanCorpus().

###Kreiranje korpusa

Da bismo pripremili tekst za obradu, kreiraÄ‡emo korpus koji se sastoji dokumenata meÄ‘u kojima svaki od njih predstavlja sadrÅ¾aj odreÄ‘ene twitter poruke. 


###UtvrÄ‘ivanje najfrekventnijih reÄi u korpusu

U uvom pristupu svaku reÄ u dokumentu tretiramo kao atribut, dok je jedna twitter poruka predstavljena kao vektor atributa. Radi jednostavnosti, zanamarujemo redosled reÄi u poruci a fokusiramo se samo na broj pojavljivanja odreÄ‘ene reÄi. 

Ovo postiÅ¾emo kreiranjem term-document matrice. Redovi matrice odnose se na termine, dok kolone odgovaraju dokumentima u kolekciji. 


Slika 2 Term - document matrica

Kreirana je dodatna funkcija findFreqWords() koja omoguÄ‡ava pronalazak najfrekventnijih reÄi meÄ‘u svim twitter porukama. 
Sagledavanjem delimiÄno proÄiÅ¡Ä‡enih podataka, ustanovljeno je da postoje reÄi Äija je frekvencija pojavljivanja velika ali nemaju veÄ‡i znaÄaj na samu analizu sentimenta. 
Stoga odluÄeno je da sledeÄ‡e reÄi eliminiÅ¡u iz twitter poruka: russian, russia, grand, prix, f, russiangrandprix, russiangp.
U tabeli 5 prikazane su promenjene liste najfrekventnijih reÄi posle ukljanjanja StopWords i datih nerelevantnih reÄi. 

Lista najfrekventnijih reÄi na poÄetku
Lista najfrekventnijih reÄi posle uklanjanja stopwords
Lista najfrekventnijih reÄi posle uklanjanja stopwords i nerelevantnih reÄi


Tabela 5:  Lista najfrekventnijih reÄi sa brojem pojavljivanja

##Kreiranje wordcloud-a
Wordcloud predstavlja zgodan alat ukoliko Å¾elimo da naglasimo neke reÄi iz teksta koje se najÄeÅ¡Ä‡e pojavljuju. Daje veÄ‡i znaÄaj onim reÄima Äija je frekvencija pojavljivanja u izvornom tekstu veÄ‡a.
Za kreiranje wordcloud-a koriÅ¡Ä‡en je paket wordcloud i istoimena funkcija kojoj prosleÄ‘ujemo korpus vector. 

Parametri:

â€¢	scale - kontroliÅ¡e razliku izmeÄ‘u najveÄ‡eg i najmanjeg fona
â€¢	max.words â€“ ograniÄava broj reÄi koje Ä‡e se prikazati
â€¢	rot.per â€“ procenat vertikalnog teksta


Slika 3 Wordcloud za pozitivne  twitter poruke

Slika 4 Wordcloud za negativne twitter poruke

##Kreiranje klasifikatora

Problem sentiment analize reÅ¡avamo reÅ¡avamo koriÅ¡Ä‡enjem sledeÄ‡ih algoritama maÅ¡inskog uÄenja: Naivni Bajes, Maksimalna entropija i Metoda potpornih vektora. 
Naivni Bajes
Kako bismo kalsifikovali twitter poruke prema njihovom sentiment na pozitivne i negativne, koriÅ¡Ä‡en je Naivni Bajes algoritam klasifikacije.

Formirani dataset sadrÅ¾i ukupno 9182 twitter poruke gde svaka od njih ima oznaku sentimenta pri Äemu su obe klase ravnomerno prisutne. 

###Kreiranje korpusa document-term matrice

S obzirom da su u dataset-u najpre navedene sve pozitivne poruke, a zatim sve negativne, neophodno je da randomizacijom izvrÅ¡imo njihovo premeÅ¡tanje na sluÄajan naÄin. Nakon toga kreiramo korpus u kome Ä‡e svaka twitter poruka biti predstavljena kao jedan dokument. 
 
Za kreiranje korpusa i ÄiÅ¡Ä‡enje podataka koristimo veÄ‡ kreiranu funkciju createAndCleanCorpus().

Potrebno je da formiramo Document-Term matricu koja odgovara dokumentima u kolekciji. Kolone matrice Äine termini, a elementi odgovaraju frekvencijama svakog termina u odreÄ‘enoj twitter poruci. Za kreiranje DTM koristimo ugraÄ‘enu funkciju DocumentTermMatrix iz biblioteke tm. 


###Particionisanje podataka

KostiÄ‡emo funkciju createDataPartition() da  podelimo dati dataset na deo za trening i deo za testiranje prema razmeri 80:20.
TreniraÄ‡emo NaÃ¯ve Bayes klasifikator na trening dataset-u a zatim njegove performance proveriti na test dataset-u. Trenutna proporcija pozitivnih i negativnih poruka iznosti 50:50. 
ProveriÄ‡emo da je tokom postupka particionisanja saÄuvana ista proporcija u delu za trening i obuku. Kako bismo to proverili kreirana je dodatna funkcija frqtab().


Slika 5: Provera proporcije podataka izmeÄ‘u klasa nakon particionisanja


###Selekcija atributa 

Kreirana Document-term matrica (DTM) sadrÅ¾i 5372 atributa. S obzirom da nisu svi atributi korisni za klasifikaciju, izvrÅ¡iÄ‡emo redukciju atributa ignoriÅ¡uÄ‡i one reÄi koje se pojavljuju u manje od 50 twitter poruka. 

OgraniÄiÄ‡emo DTM da koristi samo Å¾eljene reÄi pomoÄ‡u opcije dictionary. 



Nakon selekcije atributa dimenzije matrice za trening iznose 7346 x167 dok su dimenzije matrice za testiranje 1836 x167.


###Algoritam Naivni Bajes

Naivni Bajes, algoritam za klasifikaciju teksta u suÅ¡tini predstavlja primenu Bajesove teoreme, sa jakim pretpostavkama nezavisnosti. 

U ovom radu koriÅ¡Ä‡ena je varijacija Multinominalnog Naivnog Bajes-a koji je poznat kao binarizovani (Boolean feature) Naivni Bajes. Frekvencije termina zamenjujemo jednostavnim prisustvom tj. odsustvom odreÄ‘enog termina. 

Za treniranje modela koriÅ¡Ä‡ena je funkcija naiveBayes iz biblioteke e1071. S obzirom da Naivni Bajes izraÄunava proizvode verovatnoÄ‡a, moramo obezbediti naÄin da izbegnemo dodeljivanje nule onim reÄima koje nisu prisutne u poruci. Zbog toda koristimo parameter laplace, koji ima vrednost 1. 



Nakon testiranja dobijenog klasifikatora na test dataset-u kreiramo matricu konfuzije sa rezultatima prikazanim na slici 6. 

Slika 6 Rezultati dobijenog klasifikatora - Naivni Bajes

###Kros validacija â€“ Naivni Bajes

Kros validacija predstavlja postupak kojim se originalni dataset deli na k jednakih delova (eng. folds). Na taj naÄin trening se vrÅ¡i nad k-1 delova dok jedan deo preostaje za validaciju. Dati process se ponavlja k puta tako Å¡to se svaki put razliÄiti deo koristi za validaciju. Nakon toga izraÄunava se prosek svih iteracija. 

Cilj kros validacije je da se spreÄi problem overfitting-a, a da se predikcije uÄine generalnijim. 
Za potrebe kros validacije, koriÅ¡Ä‡ena je bibliotaka caret koja pruÅ¾a funkcionalnost stratifikovane kros-validacije Å¡to znaÄi da se u svakom od dobijenih delova nalazi odgovarajuÄ‡a proporcija podataka meÄ‘u klasama. 

Rezultati dobijenog modela kros validacijom sa podelom na 10 delova (folds=10) prikazani su na slici 7. TaÄnost ovog modela Naivnog Bajesa iznosi 44.9%.






Slika 7 Rezultati kros validacije - Naivni Bajes


###Razmatranje rezultata modela Naivni Bajes

TaÄnost predviÄ‘anja modela klasifikacije iskazuje se procentom ispravno predviÄ‘enih instanci u odnosu na njihov ukupan broj. 
Preciznost za ovaj model iznosi skromnih 42%. S obzirom na inaÄe odliÄne performance ove metode, dobijene loÅ¡e rezultate moÅ¾emo jedino prepisati nereprezentativnim prikupljenim podacima. Stoga je planirani korak dalje analize ponoviti opisani postupak nad novim podacima. 


##Metoda maksimalne entropije 

Metoda maksimalne entropije predstavlja jedan od modela logistiÄke regresije. Pripada klasi eksponencijalnih modela. Za razliku od Naivnog Bajesa, model maksimalne entropije ne pretpostavlja uslovnu nezavisnost meÄ‘u atributima. Metod maksimalne entropije zasniva se na principu maksimalne entropije i od svih modela koji odgovaraju trening podacima, bira onaj koji poseduje najveÄ‡u entropiju. 

Ova metoda se osim za problem analize sentimenta Äesto koristi za Å¡iroku klasu problema klasifikacije teksta kao Å¡to su detekcija jezika, klasifikacija tema i druge. 


Kako bismo kreirali model maksimalne entropije koristimo biblioteku RTextTools, koja u pozadini koristi veÄ‡ koriÅ¡Ä‡enu biblioteku e1071. Dobijene performanse algoritma prikazane su na slici 8. 


Slika 8 Performanse algoritma - MAXENT

###Kros validacija â€“ Metoda maksimalne entropije 

Kao i kod metode Naivnog Bajesa i za metodu maksimalne entropije izvrÅ¡ena je kros validacija (folds=10). 
Dobijeni su sledeÄ‡i rezultati:


Slika 9 Rezultati kros validacije - MAXENT





S obzirom da preciznost dobijenog modela maksimalne entropije iznosi 50.8% zakljuÄujemo da je metod maksimalne entropije imao neznatno bolje performance od algoritma Naivni Bajes. 

##Metoda potpornih vektora

Metoda potpornih (podrÅ¾avajuÄ‡ih) vektora predstavlja joÅ¡ jednu od tehnika klasifikacije. Osnovna ideja jeste naÄ‡i hiper-ravan koja razdvaja podatke tako da su svi podaci jedne klase sa iste strane date ravni. 

U ovom radu koriÅ¡Ä‡ena je metoda potpornih vektora sa linearnim jezgrom. Zadatak treniranja podataka podrazumeva pronalazak optimalne linearne ravni koja razdvaja podatke za trening. Optimalna hiper-ravan je ona koja poseduje maksimalnu marginu odnosno rastojanje meÄ‘u podacima za trening. Kao rezultat dobijamo hiper-ravan koja je potpuno odreÄ‘ena podskupom podataka za trening koji se nazivaju podrÅ¾avajuÄ‡i (potporni) vektori. 

Na sliÄan naÄin kao i kod metoda maksimalne verodostojnosti kreiran je klasifikator zasnovan na metodi potpornih vektora koriÅ¡Ä‡enjem R biblioteke RTextTools.

Dobijene performance algoritma predstavljene su na slici 9.



Slika 10 Performanse algoritma - SVM

###Kros validacija â€“ Metoda potpornih vektora 

Nakon izvrÅ¡ene kros validacije za model zasnovan na potpornim vektorima dobijeni su sledeÄ‡i rezultati:


Slika 11 Rezultati kros validacije - SVM



##PoreÄ‘enje dobijenih klasifikatora

Nakon terstiranja klasifikatora Naivni Bajes, Maksimalna entropija i metoda potpornih vektora zakljuÄeno je da najbolje performance pruÅ¾a metoda maksimalne entropije. 
Dobijene taÄnosti datih algorima tokom kros validacije uporeÄ‘ene su u tabeli 6. 

Naivni Bajes
Maksimalna entropija
Metoda potpornih vektora
TaÄnost
40.9%
50.8%
38.4%
Tabela 6  PoreÄ‘enje algoritama
 

##Literatura
[1] Go A, Bhyani R, Huang L, â€Twitter Sentiment Classification using Distant Supervisionâ€œ, pages 1-6 
[2] Vieweg, S., Palen, L., Liu, S. B., Hughes, A. L., and Sutton, J., â€œCollective intelligence in disaster: An examination of the phenomenon in the aftermath of the 2007 Virginia Tech shootings.â€, In Proceedings of the Information Systems for Crisis Response and Management Conference (ISCRAM). 2008.

[3] Bo Pang and Lillian Lee Sentiment analysis and opinion mining, Foundations and Tredns in Information Retrieval, Volume 2 Issue 1-2, January 2008. 
[4] B. Pang, L. Lee, and S. Vaithyanathan, Thumbs up? Sentiment classification using machine learning techniques, in Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP), pp. 79â€“86, 2002. 
